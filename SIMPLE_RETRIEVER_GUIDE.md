# Simple PDF Retriever with RecursiveCharacterTextSplitter

## Overview

Your new `SimplePDFRetriever` provides an efficient, easy-to-use way to search PDF documents using:

âœ… **RecursiveCharacterTextSplitter** - Intelligent chunking at natural text boundaries
âœ… **Chroma Vector Store** - Fast, lightweight in-memory vector database
âœ… **OpenAI Embeddings** - High-quality semantic search
âœ… **Cohere Reranking** - Optional reranking for better precision

## Test Results

Successfully processed "Thief of Sorrows":
- **353 pages** loaded
- **970 chunks** created (1000 chars each, 200 char overlap)
- **Accurate retrieval** across all test queries

## Quick Start

### 1. Basic Usage

```python
from book_research.simple_pdf_retriever import create_simple_pdf_retriever

# Create retriever (one line!)
retriever = create_simple_pdf_retriever("book.pdf")

# Search
results = retriever.search("What happens in chapter 2?", k=5)

# Display results
for result in results:
    print(f"Page {result.metadata['page_number']}:")
    print(result.page_content)
```

### 2. Custom Configuration

```python
retriever = create_simple_pdf_retriever(
    pdf_path="book.pdf",
    chunk_size=1000,       # Larger chunks = more context
    chunk_overlap=200,     # Overlap = better continuity
    k=5,                   # Number of results
    use_reranking=True     # Enable Cohere reranking
)
```

### 3. Integrate with Existing Agent

Replace your current PDF retriever in `main.py`:

```python
# OLD (complex ensemble retriever)
from langchain.retrievers import EnsembleRetriever
from langchain.retrievers.multi_query import MultiQueryRetriever
# ... lots of setup code ...

# NEW (simple and effective)
from book_research.simple_pdf_retriever import create_simple_pdf_retriever

pdf_retriever = create_simple_pdf_retriever(
    pdf_path="book_research/data/thief_of_sorrows.pdf",
    openai_api_key=openai_api_key,
    cohere_api_key=cohere_api_key,
    chunk_size=1000,
    chunk_overlap=200,
    k=5
)

# Use .retriever property to get the underlying LangChain retriever
pdf_retriever_for_agent = pdf_retriever.retriever
```

## How RecursiveCharacterTextSplitter Works

The splitter tries to split at natural boundaries in this order:

1. **Paragraph breaks** (`\n\n`) - Keeps full paragraphs together
2. **Line breaks** (`\n`) - Splits at line boundaries
3. **Sentences** (`. `) - Keeps sentences intact
4. **Clauses** (`, `) - Splits at commas if needed
5. **Words** (` `) - Splits at word boundaries
6. **Characters** - Last resort

### Benefits

- **Better context preservation** - Doesn't cut mid-sentence
- **Consistent chunk sizes** - ~1000 chars per chunk
- **Overlap for continuity** - 200 chars overlap prevents information loss
- **Semantic coherence** - Chunks are more meaningful

## Comparison: Old vs New

### Old Approach (Complex)
```python
# Multiple retrievers
csv_vectorstore = Qdrant.from_documents(...)
csv_bm25 = BM25Retriever.from_documents(...)
csv_multi_query = MultiQueryRetriever.from_llm(...)
csv_compression = ContextualCompressionRetriever(...)
csv_retriever = EnsembleRetriever(
    retrievers=[csv_bm25, csv_multi_query, csv_compression],
    weights=[0.2, 0.3, 0.5]
)
# Result: Complex, hard to debug, many moving parts
```

### New Approach (Simple)
```python
# One line
retriever = create_simple_pdf_retriever("book.pdf")
# Result: Clean, fast, easy to understand
```

## Run the Test

```bash
python test_simple_retriever.py
```

You should see:
- PDF loading (353 pages)
- Chunking (970 chunks created)
- 4 test queries with relevant results

## File Locations

- **Module:** `book_research/simple_pdf_retriever.py`
- **Test Script:** `test_simple_retriever.py`
- **This Guide:** `SIMPLE_RETRIEVER_GUIDE.md`

## Next Steps

### Option 1: Replace Current PDF Retriever in main.py

Update lines 357-393 in `main.py` to use the simple retriever instead of the complex ensemble setup.

### Option 2: Use Alongside Current System

Keep both and compare performance to see which works better for your use case.

### Option 3: Customize Further

Adjust chunk size, overlap, and reranking parameters based on your specific needs:

- **Smaller chunks (500)** - More precise, but less context
- **Larger chunks (2000)** - More context, but less precise
- **More overlap (400)** - Better continuity, more storage
- **Less overlap (100)** - Less storage, potential gaps

## Performance Notes

- **Initialization:** ~5-10 seconds (loads PDF, creates embeddings)
- **Search:** ~1-2 seconds per query (with reranking)
- **Memory:** Lightweight (in-memory Chroma, ~50MB for 970 chunks)
- **Accuracy:** High quality with Cohere reranking enabled

## Troubleshooting

### "OpenAI API key required"
Make sure `.env` file has `OPENAI_API_KEY=your-key-here`

### "Cohere API key missing"
Reranking will be disabled automatically. Set `COHERE_API_KEY` or use `use_reranking=False`

### Slow searches
Reduce `k` parameter or disable reranking for faster (but less accurate) results

## Summary

You now have a **simple, efficient PDF retriever** that:

âœ… Uses RecursiveCharacterTextSplitter for intelligent chunking
âœ… Provides accurate semantic search with embeddings
âœ… Is easy to use, customize, and integrate
âœ… Has been tested and verified to work

Enjoy your improved book search! ðŸ“š
